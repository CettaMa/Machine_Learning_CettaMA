{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cetta Maulana Andhika\n",
    "1103213119\n",
    "TK-45-04\n",
    "dataset : credit_score.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import semua library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report,mean_absolute_error,mean_absolute_percentage_error,mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baca Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cetta\\AppData\\Local\\Temp\\ipykernel_18948\\3591381227.py:1: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"datatset\\\\train.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 28 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   ID                        100000 non-null  object \n",
      " 1   Customer_ID               100000 non-null  object \n",
      " 2   Month                     100000 non-null  object \n",
      " 3   Name                      90015 non-null   object \n",
      " 4   Age                       100000 non-null  object \n",
      " 5   SSN                       100000 non-null  object \n",
      " 6   Occupation                100000 non-null  object \n",
      " 7   Annual_Income             100000 non-null  object \n",
      " 8   Monthly_Inhand_Salary     84998 non-null   float64\n",
      " 9   Num_Bank_Accounts         100000 non-null  int64  \n",
      " 10  Num_Credit_Card           100000 non-null  int64  \n",
      " 11  Interest_Rate             100000 non-null  int64  \n",
      " 12  Num_of_Loan               100000 non-null  object \n",
      " 13  Type_of_Loan              88592 non-null   object \n",
      " 14  Delay_from_due_date       100000 non-null  int64  \n",
      " 15  Num_of_Delayed_Payment    92998 non-null   object \n",
      " 16  Changed_Credit_Limit      100000 non-null  object \n",
      " 17  Num_Credit_Inquiries      98035 non-null   float64\n",
      " 18  Credit_Mix                100000 non-null  object \n",
      " 19  Outstanding_Debt          100000 non-null  object \n",
      " 20  Credit_Utilization_Ratio  100000 non-null  float64\n",
      " 21  Credit_History_Age        90970 non-null   object \n",
      " 22  Payment_of_Min_Amount     100000 non-null  object \n",
      " 23  Total_EMI_per_month       100000 non-null  float64\n",
      " 24  Amount_invested_monthly   95521 non-null   object \n",
      " 25  Payment_Behaviour         100000 non-null  object \n",
      " 26  Monthly_Balance           98800 non-null   object \n",
      " 27  Credit_Score              100000 non-null  object \n",
      "dtypes: float64(4), int64(4), object(20)\n",
      "memory usage: 21.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"datatset\\\\train.csv\")\n",
    "\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Meta\n",
    "data = data.drop(columns=['ID',\"Customer_ID\",\"SSN\",\"Credit_History_Age\",'Name',\"Type_of_Loan\"]) \n",
    "data = data.dropna(axis=0) #Drop missing data row\n",
    "data = data.applymap(lambda x: x.replace('_', '') if isinstance(x, str) else x) #dremove \"_\" in data\n",
    "\n",
    "#Convert categorical columns into categorical numerical\n",
    "categorical = ['Month',\"Occupation\",\"Credit_Mix\",\"Payment_of_Min_Amount\",\"Payment_Behaviour\",\"Credit_Score\"]\n",
    "label_encoder = LabelEncoder()\n",
    "for x in categorical:\n",
    "    data[x] = label_encoder.fit_transform(data[x])\n",
    "\n",
    "# Filter out negative values in numeric columns\n",
    "data = data.apply(pd.to_numeric,errors='coerce')\n",
    "data = data.applymap(lambda x: x if x >= 0 else None)\n",
    "data.dropna(axis=0,inplace=True)\n",
    "\n",
    "# Calculate quartiles for each feature\n",
    "quartiles = data.quantile([0.25, 0.75])\n",
    "\n",
    "# Calculate IQR (Interquartile Range) for each feature\n",
    "IQR = quartiles.loc[0.75] - quartiles.loc[0.25]\n",
    "\n",
    "# Define lower and upper bounds for each feature\n",
    "lower_bound = (quartiles.loc[0.25] - 1.5 * IQR).to_dict()\n",
    "upper_bound = (quartiles.loc[0.75] + 1.5 * IQR).to_dict()\n",
    "\n",
    "# Filter out data points outside the bounds for each feature\n",
    "filtered_data = data.copy()\n",
    "for feature in data.columns:\n",
    "    lower_bound_value = lower_bound[feature]\n",
    "    upper_bound_value = upper_bound[feature]\n",
    "    filtered_data = filtered_data[(filtered_data[feature] >= lower_bound_value) & (filtered_data[feature] <= upper_bound_value)]\n",
    "data = filtered_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7089895808093046\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.57      0.56       674\n",
      "           1       0.71      0.67      0.69      1185\n",
      "           2       0.75      0.77      0.76      2268\n",
      "\n",
      "    accuracy                           0.71      4127\n",
      "   macro avg       0.67      0.67      0.67      4127\n",
      "weighted avg       0.71      0.71      0.71      4127\n",
      "\n",
      "Mean Absolute Error: 0.4099830385267749\n",
      "Mean Absolute Percentage Error (MAPE): 613283981241148.2\n",
      "Mean Squared Error (MSE): 0.6479282771989339\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "X = data.drop('Credit_Score', axis=1)  # Replace 'target_variable_name' with the name of your target variable\n",
    "y = data['Credit_Score']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize KNN classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=10)  # You can adjust the number of neighbors\n",
    "\n",
    "# Train the KNN classifier\n",
    "knn_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict the labels for test set\n",
    "y_pred = knn_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "mean_error = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error:\", mean_error)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7872546644051369\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71      1323\n",
      "           1       0.77      0.79      0.78      2353\n",
      "           2       0.81      0.81      0.81      4578\n",
      "\n",
      "    accuracy                           0.79      8254\n",
      "   macro avg       0.77      0.76      0.77      8254\n",
      "weighted avg       0.79      0.79      0.79      8254\n",
      "\n",
      "Mean Absolute Error: 0.2984007753816331\n",
      "Mean Absolute Percentage Error (MAPE): 437592306899823.0\n",
      "Mean Squared Error (MSE): 0.46971165495517325\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust the number of estimators\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "mean_error = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error:\", mean_error)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1669620205.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 21\u001b[1;36m\u001b[0m\n\u001b[1;33m    mse = mean_squared_error(y_test, y_pred):\u001b[0m\n\u001b[1;37m                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Initialize XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', random_state=42)  \n",
    "\n",
    "# Train the XGBoost classifier\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for test set\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "mean_error = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error:\", mean_error)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
